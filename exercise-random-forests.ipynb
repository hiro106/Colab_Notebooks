{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa03111",
   "metadata": {
    "papermill": {
     "duration": 0.005547,
     "end_time": "2022-06-11T01:17:40.332175",
     "exception": false,
     "start_time": "2022-06-11T01:17:40.326628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**This notebook is an exercise in the [Introduction to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/random-forests).**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8921d",
   "metadata": {
    "papermill": {
     "duration": 0.004057,
     "end_time": "2022-06-11T01:17:40.343002",
     "exception": false,
     "start_time": "2022-06-11T01:17:40.338945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Recap\n",
    "Here's the code you've written so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c818feea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T01:17:40.354818Z",
     "iopub.status.busy": "2022-06-11T01:17:40.354087Z",
     "iopub.status.idle": "2022-06-11T01:17:41.648792Z",
     "shell.execute_reply": "2022-06-11T01:17:41.647642Z"
    },
    "papermill": {
     "duration": 1.304108,
     "end_time": "2022-06-11T01:17:41.651456",
     "exception": false,
     "start_time": "2022-06-11T01:17:40.347348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE when not specifying max_leaf_nodes: 29,653\n",
      "Validation MAE for best value of max_leaf_nodes: 27,283\n",
      "\n",
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = '../input/home-data-for-ml-course/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\n",
    "# Using best value for max_leaf_nodes\n",
    "iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\n",
    "iowa_model.fit(train_X, train_y)\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.machine_learning.ex6 import *\n",
    "print(\"\\nSetup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5f8f1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T01:17:41.663677Z",
     "iopub.status.busy": "2022-06-11T01:17:41.662688Z",
     "iopub.status.idle": "2022-06-11T01:17:41.671819Z",
     "shell.execute_reply": "2022-06-11T01:17:41.670726Z"
    },
    "papermill": {
     "duration": 0.018225,
     "end_time": "2022-06-11T01:17:41.674758",
     "exception": false,
     "start_time": "2022-06-11T01:17:41.656533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learntools.core.globals_binder.Binder"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(binder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e070d5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T01:17:41.686263Z",
     "iopub.status.busy": "2022-06-11T01:17:41.685863Z",
     "iopub.status.idle": "2022-06-11T01:17:41.693175Z",
     "shell.execute_reply": "2022-06-11T01:17:41.692081Z"
    },
    "papermill": {
     "duration": 0.015673,
     "end_time": "2022-06-11T01:17:41.695493",
     "exception": false,
     "start_time": "2022-06-11T01:17:41.679820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "builtin_function_or_method"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(globals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dfdac3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T01:17:41.707713Z",
     "iopub.status.busy": "2022-06-11T01:17:41.706924Z",
     "iopub.status.idle": "2022-06-11T01:17:41.713530Z",
     "shell.execute_reply": "2022-06-11T01:17:41.712525Z"
    },
    "papermill": {
     "duration": 0.015313,
     "end_time": "2022-06-11T01:17:41.715727",
     "exception": false,
     "start_time": "2022-06-11T01:17:41.700414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd244cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T01:17:41.728225Z",
     "iopub.status.busy": "2022-06-11T01:17:41.727583Z",
     "iopub.status.idle": "2022-06-11T01:17:41.733849Z",
     "shell.execute_reply": "2022-06-11T01:17:41.732898Z"
    },
    "papermill": {
     "duration": 0.014962,
     "end_time": "2022-06-11T01:17:41.736074",
     "exception": false,
     "start_time": "2022-06-11T01:17:41.721112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function globals()>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6c4911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T01:17:41.748687Z",
     "iopub.status.busy": "2022-06-11T01:17:41.748062Z",
     "iopub.status.idle": "2022-06-11T01:17:41.800734Z",
     "shell.execute_reply": "2022-06-11T01:17:41.799518Z"
    },
    "papermill": {
     "duration": 0.061445,
     "end_time": "2022-06-11T01:17:41.803000",
     "exception": false,
     "start_time": "2022-06-11T01:17:41.741555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['',\n",
       "  '# Code you have previously used to load data\\nimport pandas as pd\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.tree import DecisionTreeRegressor\\n\\n\\n# Path of the file to read\\niowa_file_path = \\'../input/home-data-for-ml-course/train.csv\\'\\n\\nhome_data = pd.read_csv(iowa_file_path)\\n# Create target object and call it y\\ny = home_data.SalePrice\\n# Create X\\nfeatures = [\\'LotArea\\', \\'YearBuilt\\', \\'1stFlrSF\\', \\'2ndFlrSF\\', \\'FullBath\\', \\'BedroomAbvGr\\', \\'TotRmsAbvGrd\\']\\nX = home_data[features]\\n\\n# Split into validation and training data\\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\\n\\n# Specify Model\\niowa_model = DecisionTreeRegressor(random_state=1)\\n# Fit Model\\niowa_model.fit(train_X, train_y)\\n\\n# Make validation predictions and calculate mean absolute error\\nval_predictions = iowa_model.predict(val_X)\\nval_mae = mean_absolute_error(val_predictions, val_y)\\nprint(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\\n\\n# Using best value for max_leaf_nodes\\niowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\\niowa_model.fit(train_X, train_y)\\nval_predictions = iowa_model.predict(val_X)\\nval_mae = mean_absolute_error(val_predictions, val_y)\\nprint(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\\n\\n\\n# Set up code checking\\nfrom learntools.core import binder\\nbinder.bind(globals())\\nfrom learntools.machine_learning.ex6 import *\\nprint(\"\\\\nSetup complete\")',\n",
       "  'type(binder)',\n",
       "  'type(globals)',\n",
       "  'type(globals())',\n",
       "  'globals',\n",
       "  'globals()'],\n",
       " '_oh': {2: learntools.core.globals_binder.Binder,\n",
       "  3: builtin_function_or_method,\n",
       "  4: dict,\n",
       "  5: <function globals()>},\n",
       " '_dh': ['/kaggle/working'],\n",
       " 'In': ['',\n",
       "  '# Code you have previously used to load data\\nimport pandas as pd\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.tree import DecisionTreeRegressor\\n\\n\\n# Path of the file to read\\niowa_file_path = \\'../input/home-data-for-ml-course/train.csv\\'\\n\\nhome_data = pd.read_csv(iowa_file_path)\\n# Create target object and call it y\\ny = home_data.SalePrice\\n# Create X\\nfeatures = [\\'LotArea\\', \\'YearBuilt\\', \\'1stFlrSF\\', \\'2ndFlrSF\\', \\'FullBath\\', \\'BedroomAbvGr\\', \\'TotRmsAbvGrd\\']\\nX = home_data[features]\\n\\n# Split into validation and training data\\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\\n\\n# Specify Model\\niowa_model = DecisionTreeRegressor(random_state=1)\\n# Fit Model\\niowa_model.fit(train_X, train_y)\\n\\n# Make validation predictions and calculate mean absolute error\\nval_predictions = iowa_model.predict(val_X)\\nval_mae = mean_absolute_error(val_predictions, val_y)\\nprint(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\\n\\n# Using best value for max_leaf_nodes\\niowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\\niowa_model.fit(train_X, train_y)\\nval_predictions = iowa_model.predict(val_X)\\nval_mae = mean_absolute_error(val_predictions, val_y)\\nprint(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\\n\\n\\n# Set up code checking\\nfrom learntools.core import binder\\nbinder.bind(globals())\\nfrom learntools.machine_learning.ex6 import *\\nprint(\"\\\\nSetup complete\")',\n",
       "  'type(binder)',\n",
       "  'type(globals)',\n",
       "  'type(globals())',\n",
       "  'globals',\n",
       "  'globals()'],\n",
       " 'Out': {2: learntools.core.globals_binder.Binder,\n",
       "  3: builtin_function_or_method,\n",
       "  4: dict,\n",
       "  5: <function globals()>},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f5b24886190>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7f5b248a1450>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7f5b248a1450>,\n",
       " '_': <function globals()>,\n",
       " '__': dict,\n",
       " '___': builtin_function_or_method,\n",
       " '_i': 'globals',\n",
       " '_ii': 'type(globals())',\n",
       " '_iii': 'type(globals)',\n",
       " '_i1': '# Code you have previously used to load data\\nimport pandas as pd\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.tree import DecisionTreeRegressor\\n\\n\\n# Path of the file to read\\niowa_file_path = \\'../input/home-data-for-ml-course/train.csv\\'\\n\\nhome_data = pd.read_csv(iowa_file_path)\\n# Create target object and call it y\\ny = home_data.SalePrice\\n# Create X\\nfeatures = [\\'LotArea\\', \\'YearBuilt\\', \\'1stFlrSF\\', \\'2ndFlrSF\\', \\'FullBath\\', \\'BedroomAbvGr\\', \\'TotRmsAbvGrd\\']\\nX = home_data[features]\\n\\n# Split into validation and training data\\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\\n\\n# Specify Model\\niowa_model = DecisionTreeRegressor(random_state=1)\\n# Fit Model\\niowa_model.fit(train_X, train_y)\\n\\n# Make validation predictions and calculate mean absolute error\\nval_predictions = iowa_model.predict(val_X)\\nval_mae = mean_absolute_error(val_predictions, val_y)\\nprint(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\\n\\n# Using best value for max_leaf_nodes\\niowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\\niowa_model.fit(train_X, train_y)\\nval_predictions = iowa_model.predict(val_X)\\nval_mae = mean_absolute_error(val_predictions, val_y)\\nprint(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\\n\\n\\n# Set up code checking\\nfrom learntools.core import binder\\nbinder.bind(globals())\\nfrom learntools.machine_learning.ex6 import *\\nprint(\"\\\\nSetup complete\")',\n",
       " 'pd': <module 'pandas' from '/opt/conda/lib/python3.7/site-packages/pandas/__init__.py'>,\n",
       " 'mean_absolute_error': <function sklearn.metrics._regression.mean_absolute_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')>,\n",
       " 'train_test_split': <function sklearn.model_selection._split.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)>,\n",
       " 'DecisionTreeRegressor': sklearn.tree._classes.DecisionTreeRegressor,\n",
       " 'iowa_file_path': '../input/home-data-for-ml-course/train.csv',\n",
       " 'home_data':         Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       " 0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       " 1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       " 2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       " 3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       " 4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       " ...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       " 1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       " 1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       " 1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       " 1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       " 1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       " \n",
       "      LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       " 0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       " 1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       " 2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       " 3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       " 4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       " ...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       " 1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       " 1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       " 1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       " 1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       " 1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       " \n",
       "      MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       " 0         2   2008        WD         Normal     208500  \n",
       " 1         5   2007        WD         Normal     181500  \n",
       " 2         9   2008        WD         Normal     223500  \n",
       " 3         2   2006        WD        Abnorml     140000  \n",
       " 4        12   2008        WD         Normal     250000  \n",
       " ...     ...    ...       ...            ...        ...  \n",
       " 1455      8   2007        WD         Normal     175000  \n",
       " 1456      2   2010        WD         Normal     210000  \n",
       " 1457      5   2010        WD         Normal     266500  \n",
       " 1458      4   2010        WD         Normal     142125  \n",
       " 1459      6   2008        WD         Normal     147500  \n",
       " \n",
       " [1460 rows x 81 columns],\n",
       " 'y': 0       208500\n",
       " 1       181500\n",
       " 2       223500\n",
       " 3       140000\n",
       " 4       250000\n",
       "          ...  \n",
       " 1455    175000\n",
       " 1456    210000\n",
       " 1457    266500\n",
       " 1458    142125\n",
       " 1459    147500\n",
       " Name: SalePrice, Length: 1460, dtype: int64,\n",
       " 'features': ['LotArea',\n",
       "  'YearBuilt',\n",
       "  '1stFlrSF',\n",
       "  '2ndFlrSF',\n",
       "  'FullBath',\n",
       "  'BedroomAbvGr',\n",
       "  'TotRmsAbvGrd'],\n",
       " 'X':       LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
       " 0        8450       2003       856       854         2             3   \n",
       " 1        9600       1976      1262         0         2             3   \n",
       " 2       11250       2001       920       866         2             3   \n",
       " 3        9550       1915       961       756         1             3   \n",
       " 4       14260       2000      1145      1053         2             4   \n",
       " ...       ...        ...       ...       ...       ...           ...   \n",
       " 1455     7917       1999       953       694         2             3   \n",
       " 1456    13175       1978      2073         0         2             3   \n",
       " 1457     9042       1941      1188      1152         2             4   \n",
       " 1458     9717       1950      1078         0         1             2   \n",
       " 1459     9937       1965      1256         0         1             3   \n",
       " \n",
       "       TotRmsAbvGrd  \n",
       " 0                8  \n",
       " 1                6  \n",
       " 2                6  \n",
       " 3                7  \n",
       " 4                9  \n",
       " ...            ...  \n",
       " 1455             7  \n",
       " 1456             7  \n",
       " 1457             9  \n",
       " 1458             5  \n",
       " 1459             6  \n",
       " \n",
       " [1460 rows x 7 columns],\n",
       " 'train_X':       LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
       " 6       10084       2004      1694         0         2             3   \n",
       " 807     21384       1923      1072       504         1             3   \n",
       " 955      7136       1946       979       979         2             4   \n",
       " 1040    13125       1957      1803         0         2             3   \n",
       " 701      9600       1969      1164         0         1             3   \n",
       " ...       ...        ...       ...       ...       ...           ...   \n",
       " 715     10140       1974      1350         0         2             3   \n",
       " 905      9920       1954      1063         0         1             3   \n",
       " 1096     6882       1914       773       582         1             3   \n",
       " 235      1680       1971       483       504         1             2   \n",
       " 1061    18000       1935       894         0         1             2   \n",
       " \n",
       "       TotRmsAbvGrd  \n",
       " 6                7  \n",
       " 807              6  \n",
       " 955              8  \n",
       " 1040             8  \n",
       " 701              6  \n",
       " ...            ...  \n",
       " 715              7  \n",
       " 905              6  \n",
       " 1096             7  \n",
       " 235              5  \n",
       " 1061             6  \n",
       " \n",
       " [1095 rows x 7 columns],\n",
       " 'val_X':       LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
       " 258     12435       2001       963       829         2             3   \n",
       " 267      8400       1939      1052       720         2             4   \n",
       " 288      9819       1967       900         0         1             3   \n",
       " 649      1936       1970       630         0         1             1   \n",
       " 1233    12160       1959      1188         0         1             3   \n",
       " ...       ...        ...       ...       ...       ...           ...   \n",
       " 1017     5814       1984      1360         0         1             1   \n",
       " 534      9056       2004       707       707         2             3   \n",
       " 1334     2368       1970       765       600         1             3   \n",
       " 1369    10635       2003      1668         0         2             3   \n",
       " 628     11606       1969      1040      1040         1             5   \n",
       " \n",
       "       TotRmsAbvGrd  \n",
       " 258              7  \n",
       " 267              8  \n",
       " 288              5  \n",
       " 649              3  \n",
       " 1233             6  \n",
       " ...            ...  \n",
       " 1017             4  \n",
       " 534              6  \n",
       " 1334             7  \n",
       " 1369             8  \n",
       " 628              9  \n",
       " \n",
       " [365 rows x 7 columns],\n",
       " 'train_y': 6       307000\n",
       " 807     223500\n",
       " 955     145000\n",
       " 1040    155000\n",
       " 701     140000\n",
       "          ...  \n",
       " 715     165000\n",
       " 905     128000\n",
       " 1096    127000\n",
       " 235      89500\n",
       " 1061     81000\n",
       " Name: SalePrice, Length: 1095, dtype: int64,\n",
       " 'val_y': 258     231500\n",
       " 267     179500\n",
       " 288     122000\n",
       " 649      84500\n",
       " 1233    142000\n",
       "          ...  \n",
       " 1017    187500\n",
       " 534     178000\n",
       " 1334    125000\n",
       " 1369    232000\n",
       " 628     135000\n",
       " Name: SalePrice, Length: 365, dtype: int64,\n",
       " 'iowa_model': DecisionTreeRegressor(max_leaf_nodes=100, random_state=1),\n",
       " 'val_predictions': array([181225.35416667, 173500.        , 122142.35714286,  94060.        ,\n",
       "        148515.31111111, 262472.95454545, 338689.66666667, 144440.84210526,\n",
       "        226811.45833333, 211678.57142857, 177621.25      , 107987.31343284,\n",
       "        235183.        , 208100.        , 262472.95454545, 107987.31343284,\n",
       "        122142.35714286, 148515.31111111, 200250.        , 139105.5       ,\n",
       "        139105.5       , 241547.375     , 211678.57142857, 391967.33333333,\n",
       "        107987.31343284, 157283.91176471, 152319.27586207, 192722.44827586,\n",
       "        572292.75      , 152319.27586207, 127746.15384615, 122142.35714286,\n",
       "        122142.35714286, 112800.        , 128999.51923077, 386250.        ,\n",
       "        107987.31343284, 107987.31343284, 327000.        , 124743.18181818,\n",
       "        128999.51923077, 128999.51923077, 107987.31343284, 107987.31343284,\n",
       "        181225.35416667, 177621.25      ,  94060.        , 192722.44827586,\n",
       "        235183.        , 263314.        , 122142.35714286, 355033.33333333,\n",
       "         76617.85714286, 234387.03225806, 192722.44827586, 107987.31343284,\n",
       "        122142.35714286, 181225.35416667, 128999.51923077, 157283.91176471,\n",
       "        177621.25      , 339214.33333333, 107987.31343284, 122142.35714286,\n",
       "        177621.25      , 122142.35714286, 117100.8       , 234387.03225806,\n",
       "        148515.31111111, 177621.25      , 159928.57142857, 152319.27586207,\n",
       "        338689.66666667, 157283.91176471, 128999.51923077, 192722.44827586,\n",
       "        181225.35416667, 107987.31343284, 295450.        , 192722.44827586,\n",
       "        209718.18181818, 152319.27586207, 139105.5       , 148515.31111111,\n",
       "        181225.35416667, 148515.31111111, 157283.91176471, 192722.44827586,\n",
       "        181225.35416667, 198528.125     , 192722.44827586, 148515.31111111,\n",
       "        122142.35714286, 148515.31111111, 128999.51923077, 117100.8       ,\n",
       "        122142.35714286, 128999.51923077, 122142.35714286, 148515.31111111,\n",
       "        209718.18181818, 139105.5       , 117100.8       , 122142.35714286,\n",
       "        122142.35714286, 162846.75      , 192722.44827586, 127746.15384615,\n",
       "        152319.27586207, 290534.89473684, 117100.8       , 157283.91176471,\n",
       "        148515.31111111, 192722.44827586, 205665.27777778, 181225.35416667,\n",
       "        235183.        , 122142.35714286, 204250.        , 177621.25      ,\n",
       "        152319.27586207, 235183.        , 290534.89473684, 128999.51923077,\n",
       "        283150.        , 148515.31111111, 394812.        , 122142.35714286,\n",
       "        157283.91176471, 205665.27777778, 279360.        , 122142.35714286,\n",
       "        122142.35714286, 112800.        ,  76617.85714286, 199974.375     ,\n",
       "        755000.        , 147000.        , 226811.45833333, 122142.35714286,\n",
       "        124743.18181818, 355033.33333333, 128999.51923077, 199974.375     ,\n",
       "        152319.27586207, 234387.03225806, 112800.        , 227399.06666667,\n",
       "        226811.45833333, 122142.35714286, 192722.44827586, 181225.35416667,\n",
       "        122142.35714286, 181225.35416667, 174816.66666667, 338689.66666667,\n",
       "        107987.31343284, 148515.31111111, 107987.31343284, 139105.5       ,\n",
       "        107987.31343284, 113153.83333333, 157283.91176471, 139105.5       ,\n",
       "        139105.5       , 148515.31111111, 155252.35714286, 152319.27586207,\n",
       "        135383.33333333, 124743.18181818, 226811.45833333, 162846.75      ,\n",
       "        226811.45833333, 386250.        , 181225.35416667, 139105.5       ,\n",
       "        209718.18181818, 234387.03225806, 124743.18181818, 148515.31111111,\n",
       "        122142.35714286, 181225.35416667, 135383.33333333, 122142.35714286,\n",
       "        278503.9375    , 198528.125     , 411197.33333333, 290534.89473684,\n",
       "        152319.27586207, 122142.35714286, 122142.35714286, 177621.25      ,\n",
       "         94060.        , 155252.35714286, 122142.35714286, 338689.66666667,\n",
       "        262472.95454545, 146488.88888889, 146488.88888889,  76617.85714286,\n",
       "        181225.35416667, 226811.45833333, 177621.25      , 181225.35416667,\n",
       "        318980.5       , 124743.18181818, 192722.44827586, 339214.33333333,\n",
       "        256000.        , 280000.        , 181225.35416667, 122142.35714286,\n",
       "        155252.35714286, 122142.35714286, 278503.9375    , 234387.03225806,\n",
       "        122142.35714286, 107987.31343284, 177621.25      ,  94060.        ,\n",
       "        755000.        , 122142.35714286, 155252.35714286, 148515.31111111,\n",
       "        107987.31343284, 122142.35714286, 181225.35416667, 192722.44827586,\n",
       "        181225.35416667, 181225.35416667, 124743.18181818, 174816.66666667,\n",
       "        107987.31343284, 128999.51923077, 262472.95454545, 151572.8       ,\n",
       "        290534.89473684, 122142.35714286, 204250.        , 290534.89473684,\n",
       "        278503.9375    , 157283.91176471, 122142.35714286, 173500.        ,\n",
       "        122142.35714286, 127746.15384615, 148515.31111111, 152319.27586207,\n",
       "        148515.31111111, 122142.35714286, 122142.35714286, 139105.5       ,\n",
       "        181225.35416667, 148515.31111111, 135383.33333333, 107987.31343284,\n",
       "        192722.44827586,  94060.        , 391967.33333333, 122142.35714286,\n",
       "        192722.44827586, 245416.66666667, 205665.27777778, 192722.44827586,\n",
       "         94060.        , 177621.25      , 122142.35714286, 122142.35714286,\n",
       "        148515.31111111,  94060.        , 152319.27586207, 181225.35416667,\n",
       "        124743.18181818, 144440.84210526, 157283.91176471, 128999.51923077,\n",
       "         94060.        , 122142.35714286, 198528.125     , 128999.51923077,\n",
       "        152319.27586207, 148515.31111111, 124743.18181818, 148515.31111111,\n",
       "        226811.45833333, 227399.06666667, 152319.27586207, 122142.35714286,\n",
       "        262472.95454545, 107987.31343284, 107987.31343284, 279360.        ,\n",
       "        127746.15384615, 117100.8       , 192722.44827586, 230259.8       ,\n",
       "        181225.35416667, 226811.45833333, 148515.31111111, 107987.31343284,\n",
       "        148515.31111111, 144440.84210526, 128999.51923077, 177621.25      ,\n",
       "        200250.        , 208100.        , 148515.31111111, 152319.27586207,\n",
       "        151572.8       , 192722.44827586, 148515.31111111, 157283.91176471,\n",
       "        107987.31343284, 262472.95454545, 152319.27586207, 107987.31343284,\n",
       "        234387.03225806, 181175.        , 177621.25      , 177621.25      ,\n",
       "        181225.35416667, 198528.125     , 128999.51923077, 222250.        ,\n",
       "        128999.51923077, 338689.66666667, 192722.44827586, 234387.03225806,\n",
       "        152319.27586207, 152319.27586207, 139105.5       , 177621.25      ,\n",
       "        234387.03225806, 278503.9375    , 181225.35416667, 151572.8       ,\n",
       "        139105.5       , 148515.31111111, 290534.89473684, 181225.35416667,\n",
       "        211678.57142857, 177621.25      ,  76617.85714286, 227399.06666667,\n",
       "        107987.31343284, 148515.31111111, 146488.88888889, 148515.31111111,\n",
       "        235183.        , 112800.        , 144440.84210526, 144440.84210526,\n",
       "        411197.33333333, 128999.51923077, 146488.88888889, 135383.33333333,\n",
       "        205665.27777778, 144440.84210526, 122142.35714286, 290534.89473684,\n",
       "        113153.83333333, 181225.35416667, 152319.27586207, 262472.95454545,\n",
       "        198528.125     ]),\n",
       " 'val_mae': 27282.50803885739,\n",
       " 'binder': <learntools.core.globals_binder.Binder at 0x7f5ac28014d0>,\n",
       " 'step_1': <learntools.core.problem_view.ProblemView at 0x7f5ac28168d0>,\n",
       " '____': <learntools.core.constants.PlaceholderValue at 0x7f5ac2816190>,\n",
       " '_i2': 'type(binder)',\n",
       " '_2': learntools.core.globals_binder.Binder,\n",
       " '_i3': 'type(globals)',\n",
       " '_3': builtin_function_or_method,\n",
       " '_i4': 'type(globals())',\n",
       " '_4': dict,\n",
       " '_i5': 'globals',\n",
       " '_5': <function globals()>,\n",
       " '_i6': 'globals()'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f216e25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T01:17:41.817468Z",
     "iopub.status.busy": "2022-06-11T01:17:41.816583Z",
     "iopub.status.idle": "2022-06-11T01:17:41.823152Z",
     "shell.execute_reply": "2022-06-11T01:17:41.821888Z"
    },
    "papermill": {
     "duration": 0.017537,
     "end_time": "2022-06-11T01:17:41.826715",
     "exception": false,
     "start_time": "2022-06-11T01:17:41.809178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function globals in module builtins:\n",
      "\n",
      "globals()\n",
      "    Return the dictionary containing the current scope's global variables.\n",
      "    \n",
      "    NOTE: Updates to this dictionary *will* affect name lookups in the current\n",
      "    global scope and vice-versa.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(globals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17bf818",
   "metadata": {
    "papermill": {
     "duration": 0.006029,
     "end_time": "2022-06-11T01:17:41.839263",
     "exception": false,
     "start_time": "2022-06-11T01:17:41.833234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exercises\n",
    "Data science isn't always this easy. But replacing the decision tree with a Random Forest is going to be an easy win."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad139b",
   "metadata": {
    "papermill": {
     "duration": 0.005674,
     "end_time": "2022-06-11T01:17:41.850861",
     "exception": false,
     "start_time": "2022-06-11T01:17:41.845187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1: Use a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024e60f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T01:17:41.864713Z",
     "iopub.status.busy": "2022-06-11T01:17:41.863983Z",
     "iopub.status.idle": "2022-06-11T01:17:42.405487Z",
     "shell.execute_reply": "2022-06-11T01:17:42.404072Z"
    },
    "papermill": {
     "duration": 0.551997,
     "end_time": "2022-06-11T01:17:42.408614",
     "exception": false,
     "start_time": "2022-06-11T01:17:41.856617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for Random Forest Model: 21857.15912981083\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 1.0, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_CheckRfScore\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the model. Set random_state to 1\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# fit your model\n",
    "rf_model.fit(train_X, train_y)\n",
    "\n",
    "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
    "rf_val_mae = mean_absolute_error(val_y, rf_model.predict(val_X))\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))\n",
    "\n",
    "# Check your answer\n",
    "step_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facd060c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T01:17:42.423245Z",
     "iopub.status.busy": "2022-06-11T01:17:42.422806Z",
     "iopub.status.idle": "2022-06-11T01:17:42.436947Z",
     "shell.execute_reply": "2022-06-11T01:17:42.435982Z"
    },
    "papermill": {
     "duration": 0.024089,
     "end_time": "2022-06-11T01:17:42.439134",
     "exception": false,
     "start_time": "2022-06-11T01:17:42.415045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"questionId\": \"1_CheckRfScore\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#3366cc\">Hint:</span> Review the code above with a DecisionTreeRegressor. Use the RandomForestRegressor instead"
      ],
      "text/plain": [
       "Hint: Review the code above with a DecisionTreeRegressor. Use the RandomForestRegressor instead"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"questionId\": \"1_CheckRfScore\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "rf_model = RandomForestRegressor()\n",
       "\n",
       "# fit your model\n",
       "rf_model.fit(train_X, train_y)\n",
       "\n",
       "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
       "rf_val_predictions = rf_model.predict(val_X)\n",
       "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "rf_model = RandomForestRegressor()\n",
       "\n",
       "# fit your model\n",
       "rf_model.fit(train_X, train_y)\n",
       "\n",
       "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
       "rf_val_predictions = rf_model.predict(val_X)\n",
       "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The lines below will show you a hint or the solution.\n",
    "step_1.hint() \n",
    "step_1.solution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d77e90",
   "metadata": {
    "papermill": {
     "duration": 0.006621,
     "end_time": "2022-06-11T01:17:42.452928",
     "exception": false,
     "start_time": "2022-06-11T01:17:42.446307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So far, you have followed specific instructions at each step of your project. This helped learn key ideas and build your first model, but now you know enough to try things on your own. \n",
    "\n",
    "Machine Learning competitions are a great way to try your own ideas and learn more as you independently navigate a machine learning project. \n",
    "\n",
    "# Keep Going\n",
    "\n",
    "You are ready for **[Machine Learning Competitions](https://www.kaggle.com/alexisbcook/machine-learning-competitions).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e422fe",
   "metadata": {
    "papermill": {
     "duration": 0.006424,
     "end_time": "2022-06-11T01:17:42.466151",
     "exception": false,
     "start_time": "2022-06-11T01:17:42.459727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-machine-learning/discussion) to chat with other learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.85249,
   "end_time": "2022-06-11T01:17:43.294854",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-11T01:17:30.442364",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
